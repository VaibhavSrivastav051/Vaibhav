<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Evolution 2025: The Intelligence Revolution</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=Share+Tech+Mono&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" />
</head>
<body>

    <header id="main-header">
        <nav id="navbar">
            <a href="#hero" class="nav-logo">AI Evolution 2025</a>
            <ul>
                <li><a href="#latest-models">Models</a></li>
                <li><a href="#generative-ai">Generative AI</a></li>
                <li><a href="#computer-vision">Vision</a></li>
                <li><a href="#robotics">Robotics</a></li>
                <li><a href="#healthcare">Healthcare</a></li>
                <li><a href="#edge-ai">Edge AI</a></li>
                <li><a href="#ethics">Ethics</a></li>
                <li><a href="#cybersecurity">Security</a></li>
                <li><a href="#workplace-ai">Workplace</a></li>
                <li><a href="#agi">AGI</a></li>
                <li><a href="#quantum-ai">Quantum AI</a></li>
                <li><a href="#deep-dive">Deep Dive</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <!-- HERO SECTION -->
        <section id="hero">
            <div class="hero-content">
                <h1 class="animated-title">AI Evolution 2025: The Intelligence Revolution</h1>
                <p class="subtitle">
                    <span id="typing-effect"></span>
                </p>
                <div class="cta-buttons">
                    <a href="#latest-models" class="btn">Explore Models</a>
                    <a href="#deep-dive" class="btn">View Research</a>
                </div>
            </div>
            <div id="particles-js"></div>
        </section>

        <!-- LATEST LARGE LANGUAGE MODELS & FOUNDATION MODELS -->
        <section id="latest-models" class="content-section">
            <h2>Latest Large Language & Foundation Models</h2>
            <div class="card-container">
                <!-- OpenAI Collapsible Card -->
                <div class="card is-collapsible">
                    <header class="card-header">
                        <h3>OpenAI Models</h3>
                        <span class="toggle-icon">+</span>
                    </header>
                    <div class="card-content-wrapper">
                        <div class="card-content-inner">
                            <div class="model-details"><h4>GPT-5 (Expected)</h4><p>Anticipated next-gen model, expected to set new benchmarks in performance and capabilities.</p></div>
                            <div class="model-details"><h4>GPT-4o</h4><p>An advanced multimodal model that accepts text, audio, and image as input and generates text, audio, and image outputs.</p></div>
                            <div class="model-details"><h4>GPT-4.5 "Orion" </h4><p>A (rumored) intermediate model between GPT-4 and GPT-5, potentially offering significant improvements.</p></div>
                        </div>
                    </div>
                </div>

                <!-- Google Collapsible Card -->
                <div class="card is-collapsible">
                    <header class="card-header">
                        <h3>Google Models</h3>
                        <span class="toggle-icon">+</span>
                    </header>
                    <div class="card-content-wrapper">
                        <div class="card-content-inner">
                            <div class="model-details"><h4>Gemini 2.5 pro and Flash</h4><p>The anticipated next generation of Google's flagship models,bringing significant advancements in reasoning, multimodality, and efficiency.</p></div>
                            <div class="model-details"><h4>Gemini 1.5 Flash</h4><p>A lightweight, fast, and cost-efficient model optimized for high-volume, high-frequency tasks.</p></div>
                            <div class="model-details"><h4>Gemini 1.5 Pro</h4><p>Features a massive 1M token context window (up to 2M in private preview), excelling at long-context understanding.</p></div>
                        </div>
                    </div>
                </div>

                <!-- Anthropic Collapsible Card -->
                <div class="card is-collapsible">
                    <header class="card-header">
                        <h3>Anthropic Models</h3>
                        <span class="toggle-icon">+</span>
                    </header>
                    <div class="card-content-wrapper">
                        <div class="card-content-inner">
                            <div class="model-details"><h4>Claude 3.5 Sonnet</h4><p>Sets new industry standards for graduate-level reasoning, coding, and vision, outperforming competitor models and its predecessor, Opus.</p></div>
                            <div class="model-details"><h4>Claude 3 Family (Opus, Sonnet, Haiku)</h4><p>A spectrum of models offering different balances of intelligence, speed, and cost for various enterprise needs.</p></div>
                        </div>
                    </div>
                </div>

                <!-- xAI Collapsible Card -->
                <div class="card is-collapsible">
                    <header class="card-header">
                        <h3>xAI Models</h3>
                        <span class="toggle-icon">+</span>
                    </header>
                    <div class="card-content-wrapper">
                        <div class="card-content-inner">
                            <div class="model-details"><h4>Grok-4 (Released)</h4><p>The next major version from xAI, which is a significant leap in capabilities and a strong competitor to next-gen models upon release and trained on 1.7T Parameters.</p></div>
                            <div class="model-details"><h4>Grok-3</h4><p>The current powerful model from xAI, featuring strong reasoning capabilities. Also includes a vision-capable variant (Grok-3 Vision ).</p></div>
                        </div>
                    </div>
                </div>

                <!-- Meta Collapsible Card -->
                <div class="card is-collapsible">
                    <header class="card-header">
                        <h3>Meta Models</h3>
                        <span class="toggle-icon">+</span>
                    </header>
                    <div class="card-content-wrapper">
                        <div class="card-content-inner">
                            <div class="model-details"><h4>Llama 3.1</h4><p>An improved version of Llama 3 available in 8B, 70B, and a new 405B parameter size, with enhanced capabilities and a larger context window.</p></div>
                            <div class="model-details"><h4>Llama 3</h4><p>A powerful, open-source family of models (8B and 70B) designed to be a top-performing choice for a wide range of applications.</p></div>
                        </div>
                    </div>
                </div>

                <!-- Other Leading Models Card -->
                <div class="card is-collapsible">
                    <header class="card-header">
                        <h3>Other Leading Models</h3>
                        <span class="toggle-icon">+</span>
                    </header>
                    <div class="card-content-wrapper">
                        <div class="card-content-inner">
                            <div class="model-details"><h4>DeepSeek-V2</h4><p>An open-source Mixture-of-Experts model from DeepSeek AI, offering strong performance with high computational efficiency.</p></div>
                            <div class="model-details"><h4>Qwen2</h4><p>A new series of powerful open-source models from Alibaba Cloud, ranging from 0.5B to 72B parameters.</p></div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- GENERATIVE AI & CREATIVE TOOLS -->
        <section id="generative-ai" class="content-section">
            <h2>Generative AI & Creative Tools</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Video Generation</h3>
                    <p>OpenAI Sora (20s, 1080p), Google Veo 3 (8s with sound), Runway Gen-4, Kling AI 2.0, Pika 2.2.</p>
                </div>
                <div class="card">
                    <h3>Design & Image Tools</h3>
                    <p>Figma AI (text-to-design), Adobe Firefly, Canva AI, DALL-E evolution, Midjourney, Stable Diffusion advances.</p>
                </div>
                <div class="card">
                    <h3>3D & Audio</h3>
                    <p>Procedural generation for 3D models and AI-powered music creation tools are revolutionizing digital content.</p>
                </div>
            </div>
        </section>

        <!-- COMPUTER VISION & MULTIMODAL AI -->
        <section id="computer-vision" class="content-section">
            <h2>Computer Vision & Multimodal AI</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Architecture & Foundation Models</h3>
                    <p>Vision Transformers (ViTs) are surpassing CNNs. Foundation models like SAM 2 (Segment Anything) can now process both images and videos.</p>
                </div>
                <div class="card">
                    <h3>Applications</h3>
                    <p>Real-time video analysis, medical imaging diagnostics outperforming human experts, and advanced vision for autonomous systems.</p>
                </div>
            </div>
        </section>

        <!-- ROBOTICS & PHYSICAL AI -->
        <section id="robotics" class="content-section">
            <h2>Robotics & Physical AI</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Humanoid Robots</h3>
                    <p>Tesla Optimus Gen 2 and the new electric Boston Dynamics Atlas showcase enhanced mobility. Chinese manufacturers are reaching production scale.</p>
                </div>
                <div class="card">
                    <h3>Physical AI Foundation Models</h3>
                    <p>NVIDIA's GR00T N1 is a general-purpose foundation model for humanoid robots, enabling them to learn from human demonstration.</p>
                </div>
                <div class="card">
                    <h3>Simulation & Interaction</h3>
                    <p>Platforms like Isaac Sim and Isaac Lab accelerate training. Natural language control systems are becoming standard.</p>
                </div>
            </div>
        </section>

        <!-- AI IN HEALTHCARE -->
        <section id="healthcare" class="content-section">
            <h2>AI in Healthcare</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Diagnostics & Drug Discovery</h3>
                    <p>Diagnostic AI is achieving >90% accuracy. AI-designed drugs from labs like Isomorphic are entering human trials.</p>
                </div>
                <div class="card">
                    <h3>Personalized Medicine & Surgery</h3>
                    <p>Genomics and AI integration for personalized treatments. AI-assisted robotic surgery enhances precision. Retinal AI can now infer full-body health from eye scans.</p>
                </div>
            </div>
        </section>

        <!-- EDGE AI & COMPUTING -->
        <section id="edge-ai" class="content-section">
            <h2>Edge AI & Computing</h2>
            <div class="card-container">
                <div class="card">
                    <h3>On-Device Intelligence</h3>
                    <p>Advanced NPU integration in mobile devices allows for powerful on-device processing. 50% of enterprises are projected to adopt edge computing by 2025.</p>
                </div>
                <div class="card">
                    <h3>Real-time & Efficient</h3>
                    <p>Edge AI enables low-latency inference for IoT ecosystems. Advanced chips like Infineon's PSOC Edge prioritize power efficiency.</p>
                </div>
            </div>
        </section>

        <!-- AI SAFETY & ETHICS -->
        <section id="ethics" class="content-section">
            <h2>AI Safety & Ethics</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Governance & Fairness</h3>
                    <p>New governance frameworks like the PIKOM AI Ethics Policy 2025 are being established. Significant research is focused on bias mitigation and explainable AI (XAI).</p>
                </div>
                <div class="card">
                    <h3>Alignment & Privacy</h3>
                    <p>Ensuring AI systems align with human values is a critical research area. Robust data security and privacy protection measures are paramount.</p>
                </div>
            </div>
        </section>

        <!-- AI IN CYBERSECURITY -->
        <section id="cybersecurity" class="content-section">
            <h2>AI in Cybersecurity</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Proactive Defense</h3>
                    <p>AI-powered systems excel at threat detection and automated incident response. The AI cybersecurity market reached $24.82 billion in 2024.</p>
                </div>
                <div class="card">
                    <h3>Advanced Threat Detection</h3>
                    <p>Google's Big Sleep project aims to detect zero-day exploits. Behavioral analysis and pattern recognition systems identify novel attacks.</p>
                </div>
            </div>
        </section>

        <!-- WORKPLACE AI & AUTOMATION -->
        <section id="workplace-ai" class="content-section">
            <h2>Workplace AI & Automation</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Autonomous Agents</h3>
                    <p>AI agents are beginning to automate complex workflows. 92% of executives are planning to implement process automation.</p>
                </div>
                <div class="card">
                    <h3>Augmented Intelligence</h3>
                    <p>AI is enhancing productivity through human-AI collaboration platforms and providing data-driven insights for decision support.</p>
                </div>
            </div>
        </section>

        <!-- ARTIFICIAL GENERAL INTELLIGENCE (AGI) -->
        <section id="agi" class="content-section">
            <h2>Artificial General Intelligence (AGI)</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Progress & Predictions</h3>
                    <p>OpenAI predicts AGI could be achieved as early as 2025. Models are showing increasingly advanced reasoning and problem-solving skills.</p>
                </div>
                <div class="card">
                    <h3>Market Projections</h3>
                    <p>The AGI market is projected to reach $116 billion by 2035, driven by the development of cross-domain, autonomous AI agents.</p>
                </div>
            </div>
        </section>

        <!-- QUANTUM AI -->
        <section id="quantum-ai" class="content-section">
            <h2>Quantum AI</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Hybrid Computing</h3>
                    <p>Quantum Machine Learning (QML) combines classical and quantum computing. Investment in Quantum AI reached $677.2 million in Q1 2025.</p>
                </div>
                <div class="card">
                    <h3>Optimization & Advantage</h3>
                    <p>Companies like Multiverse Computing are using quantum-inspired algorithms to achieve a 60% parameter reduction in LLMs, demonstrating areas of quantum advantage.</p>
                </div>
            </div>
        </section>

        <!-- DEEP DIVE & GLOSSARY -->
        <section id="deep-dive" class="content-section">
            <h2>Technical Deep Dive & Glossary</h2>
            <div class="card-container">
                <div class="card">
                    <h3>Kolmogorov-Arnold Networks (KANs)</h3>
                    <p>A promising new neural network architecture that places activation functions on the edges instead of nodes. They offer potentially better accuracy and interpretability than traditional MLPs.</p>
                    <pre><code class="language-python">
# Pseudo-code for a KAN layer
class KANLayer:
    def __init__(self, input_dim, output_dim, grid_size):
        self.splines = initialize_splines(input_dim, output_dim, grid_size)

    def forward(self, x):
        # Apply spline transformations on edges
        return self.splines(x)
                    </code></pre>
                </div>
                <div class="card">
                    <h3>Glossary</h3>
                    <dl>
                        <dt>Vision Transformer (ViT)</dt>
                        <dd>A type of transformer network architecture applied to image data, treating image patches as tokens.</dd>
                        <dt>Mixture of Experts (MoE)</dt>
                        <dd>A model architecture where multiple "expert" sub-networks are used, and a gating network decides which expert to use for a given input, improving efficiency.</dd>
                        <dt>Context Window</dt>
                        <dd>The amount of text (measured in tokens) that a language model can consider at one time when generating a response.</dd>
                    </dl>
                </div>
            </div>
        </section>

    </main>

    <footer id="main-footer">
        <p>&copy; 2025 AI Evolution. All rights reserved.</p>
    </footer>

    <!-- Particles.js for background effect - can be replaced with any other particle library -->
    <script src="https://cdn.jsdelivr.net/npm/particles.js@2.0.0/particles.min.js"></script>
    <script src="js.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

</body>
</html>